{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f762b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # import pickle module to save and load trained models from files\n",
    "import streamlit as st # import streamlit framework to build the web application interface\n",
    "import pandas as pd # import pandas for data manipulation and dataframe operations\n",
    "import numpy as np # import numpy for numerical computations and array operations\n",
    "from sklearn.model_selection import train_test_split # import train_test_split function to divide dataset into training and testing sets\n",
    "# import labelencoder to convert categorical labels into numeric values\n",
    "# import standardscaler to standardize feature values\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier# import decisiontreeclassifier which will be used as weak learner\n",
    "# import ensemble methods for building ensemble models\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression# import logistic regression model used as meta learner in stacking\n",
    "from sklearn.svm import SVC# import support vector classifier used in stacking and voting\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score# import evaluation metrics to measure model performance\n",
    "import seaborn as sns # import seaborn for advanced statistical plotting\n",
    "import matplotlib.pyplot as plt # import matplotlib for creating plots and visualizations\n",
    "import random# import random module to randomly sample data points\n",
    "\n",
    "\n",
    "\n",
    "# use streamlit caching to store trained models and avoid retraining\n",
    "# cache_resource ensures models are stored across reruns\n",
    "@st.cache_resource\n",
    "def train_and_save_models(X_train, y_train):\n",
    "\n",
    "    # create a weak decision tree model with maximum depth of 1\n",
    "    # max_depth=1 makes it a decision stump\n",
    "    # random_state ensures reproducibility\n",
    "    weak_model = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "\n",
    "    # train the weak model using training data\n",
    "    weak_model.fit(X_train, y_train)\n",
    "\n",
    "    # open a file in write-binary mode to save the weak model\n",
    "    with open(\"weak_model.pkl\", \"wb\") as f:\n",
    "        # serialize and store the trained model into the file\n",
    "        pickle.dump(weak_model, f)\n",
    "\n",
    "    # create bagging classifier\n",
    "    # estimator defines the base learner\n",
    "    # n_estimators is number of trees\n",
    "    # random_state ensures same random behavior every run\n",
    "    bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=None), n_estimators=50, random_state=42)\n",
    "\n",
    "    # train bagging model\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "\n",
    "    # save bagging model to file\n",
    "    with open(\"bagging_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(bagging_model, f)\n",
    "\n",
    "    # create adaboost classifier\n",
    "    # estimator is weak learner\n",
    "    # n_estimators defines number of boosting rounds\n",
    "    adb_model = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "\n",
    "    # train adaboost model\n",
    "    adb_model.fit(X_train, y_train)\n",
    "\n",
    "    # save adaboost model\n",
    "    with open(\"adb_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(adb_model, f)\n",
    "\n",
    "    # create gradient boosting classifier\n",
    "    # n_estimators defines number of boosting stages\n",
    "    # learning_rate controls contribution of each tree\n",
    "    # max_depth=1 makes weak learners\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1,random_state=42)\n",
    "\n",
    "    # train gradient boosting model\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # save gradient boosting model\n",
    "    with open(\"gb_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(gb_model, f)\n",
    "\n",
    "    # define base estimators for stacking model\n",
    "    estimators = [\n",
    "        # decision tree as first base learner\n",
    "        (\"dt\", DecisionTreeClassifier(max_depth=1)),\n",
    "        # support vector classifier with probability output enabled\n",
    "        (\"svc\", SVC(probability=True))\n",
    "    ]\n",
    "\n",
    "    # create stacking classifier\n",
    "    # estimators are base models\n",
    "    # final_estimator combines their outputs\n",
    "    # cv=5 means 5-fold cross validation for meta learner training\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    # train stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # save stacking model\n",
    "    with open(\"stacking_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(stacking_model, f)\n",
    "\n",
    "    # create voting classifier\n",
    "    # estimators define models participating in voting\n",
    "    # voting=\"soft\" means average predicted probabilities\n",
    "    voting_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"dt\", DecisionTreeClassifier(max_depth=1)),\n",
    "            (\"rf\", BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)),\n",
    "            (\"svc\", SVC(probability=True))\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "\n",
    "    # train voting model\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # save voting model\n",
    "    with open(\"voting_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(voting_model, f)\n",
    "\n",
    "    # return all trained models\n",
    "    return weak_model, bagging_model, adb_model, gb_model, stacking_model, voting_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
